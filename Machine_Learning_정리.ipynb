{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8803ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install missingno 미싱노 인스톨 : 표를 표현하는 다른 방식이다.\n",
    "# !pip install tensorflow 텐서플로 인스톨. 머신러닝. 딥러닝에 필요하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d0a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1일차\n",
    "# import 사전\n",
    "import numpy as np # 넘파이 호출\n",
    "import pandas as pd # 판다스 호출\n",
    "import matplotlib.pyplot as plt # 맷플랏립 호출\n",
    "import seaborn as sns # 씨본 호출\n",
    "from sklearn.preprocessing import MinMaxScaler # 사이킷런 실행. 스케일러 호출\n",
    "from sklearn.model_selection import train_test_split # 사이킷런 훈련데이터, 테스트 데이터 분리모듈\n",
    "from sklearn.linear_model import LogisticRegression # 사이킷런 리니어모델 - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "                                                    \n",
    "pd.read_csv()                                        # csv 파일 호출 - 불러오는 속도가 빠름\n",
    "pd.read_csv().set_index(\"w\")()                       # csv 파일 호출, 인덱스를 w로 설정\n",
    "data.head()                                          # 데이터 상위 5개 보기 - 출력량 설정 가능 \n",
    "data.tail()                                          # 데이터 하위 5개 보기 - 출력량 설정 가능\n",
    "data.info()                                          # 데이터 개요 보기, 결측값 확인, 데이터타입 확인\n",
    "data.dropna().info()                                 # 데이터에서 결측값을 제거하고 보여주기\n",
    "data.describe()                                      # 기술통계 출력\n",
    "data.dropna(inplace=True)\n",
    "data.info()                                          # 결측값 제거를 확정하고 데이터 개요보기\n",
    "data.shape                                           # 데이터 모양 보기 (행렬 갯수 보기)\n",
    "data.columns                                         # 열 이름 인덱스 추출\n",
    "data.isnull()                                        # 결측값 여부 확인\n",
    "data.isnull().sum()                                  # 결측값의 총합\n",
    "data.value_counts()                                  # 데이터의 갯수 확인\n",
    "data['x'].median()                                   # 데이터 x의 중위수 확인\n",
    "data['x'].unique()                                   # x 데이터의 고유값 확인\n",
    "data['x'].nunique()                                  # x 데이터 고유값의 갯수 확인\n",
    "data['x'].quantile(0.25)                             # x 데이터 1사분위수 확인\n",
    "data['x'].quantile(0.75)                             # x 데이터 3사분위수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹바이 가이드\n",
    "data.groupby('x').groups \n",
    "# x로 데이터를 분류한 다음 x값의 인덱스 정보들을 출력하기\n",
    "\n",
    "data.groupby('x').agg('sum') \n",
    "# x로 데이터를 분류한 다음 다른 열들의 갯수 세기(예 : 성별에 따른 다른 열들의 합)\n",
    "\n",
    "data.groupby('x').agg('sum')[['y','z']]\n",
    "# x로 데이터를 분류한 다음 y와 z의 갯수 세기\n",
    "\n",
    "data.groupby('x').agg('sum')[['y','z']].plot(kind='bar')\n",
    "# x로 데이터를 분류한 다음 y와 z의 갯수를 바 플롯으로 표현하기\n",
    "\n",
    "data.groupby('x').agg('sum')[['y','z']].plot(kind='bar',figsize=(10,5),stacked=True)\n",
    "# x로 데이터를 분류한 다음 y와 z의 갯수를 10,5 크기의 바탕에 바 플롯으로 쌓아서 표현하기\n",
    "\n",
    "data.groupby('x').agg('mean')[['y','z']] \n",
    "# x로 데이터를 분류한 다음 y와 z의 평균 구하기\n",
    "\n",
    "data.groupby(['x'])['y'].median()\n",
    "# x로 데이터를 분류한 다음 x로 분류된 y값의 중위수 구하기\n",
    "\n",
    "for grp, grp_df in data.groupby(['x']): \n",
    "# x로 데이터를 분류한 다음 grp에 x값, grp_df에 x를 제외한 나머지를 할당하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cba867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 가이드\n",
    "                                    \n",
    "pd.concat([data1,data2])                # data1,data2를 위아래로 합치기.\n",
    "data.a.map(a_dict)                      # a 딕셔너리 내용으로 데이터 a열의 값들을 변경하기\n",
    "data.drop(['x','y'],axis=1)             # x열과 y열 드랍하기 \n",
    "data.drop(columns=['x'])                # x열 드랍하기\n",
    "train.append(test)                      # 연습데이터와 훈련데이터 병합\n",
    "data[data['x']==1]                      # 데이터 x가 1인 데이터만 그룹화하기(query 함수랑 비슷)\n",
    "data.replace({'x':x_dict},inplace=True) # 데이터의 x값의 내용을 x_dict로 설정하고 바로 적용\n",
    "list(data.x.unique())                   # 데이터 x값의 고유값을 리스트로 만들기\n",
    "pd.qcut(data['x'],5)                    # 데이터를 x값을 기준으로 5분할하여 구간나누기\n",
    "data['x'].astype(int)                   # 데이터 x를 int로 타입변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cab677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티인덱스\n",
    "pd.crosstab([data['x'],data['y']], data['z'])                  # 크로스테이블. 데이터x,y,z를 멀티인덱스로 하여 표시하기\n",
    "pd.crosstab([data['x'],data['y']], data['z'],margins=True)     # 크로스테이블. 데이터x,y,z , 총합을 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno            # 미싱노 임포트\n",
    "msno.bar(data)                      # 데이터를 미싱노 바 그래프로 표시\n",
    "msno.bar(df, color=\"blue\")          # 데이터를 미싱노 파랑바 그래프로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맷플랏립 가이드 \n",
    "plt.figure(figsize=(8,6))\n",
    "# 도화지 사이즈를 8x6으로 설정\n",
    "\n",
    "plt.scatter(data1,data2,c='r',marker='D') \n",
    "# 점으로 데이터1, 데이터2 표시, 색은 빨강, 마커는 다이아몬드 모양 \n",
    "\n",
    "plt.hist(data[data['x']==1]['y']) \n",
    "#  데이터 x가 1인 데이터만 그룹화하여 히스토그램으로 표현하기\n",
    "\n",
    "plt.hist([data[data['x']==1]['y'],data[data['x']==0]['y']])\n",
    "# 데이터 x가 0,1인 데이터와 y인 데이터를 각각 히스토그램으로 표현하기\n",
    "\n",
    "plt.hist([data[data['x']==1]['y'],data[data['x']==0]['y']],stacked=True)\n",
    "# 데이터 x가 0,1인 데이터와 y인 데이터를 각각 히스토그램으로 쌓아서 표현하기\n",
    "\n",
    "plt.hist([data[data['x']==1]['y'],data[data['x']==0]['y']],stacked=True,label=['x1','x2'],bins=50)\n",
    "# 데이터 x가 0,1인 데이터와 y인 데이터를 각각 총 50분할로 히스토그램으로 쌓아서 x1,x2이름 붙여서 나타내기.\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "# 위의 x축을 x1으로 y축을 x2로 설정하여 같이 표현하기.\n",
    "\n",
    "plt.subplots(1,2) \n",
    "# 1행 2열의 칸을 만들기\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=[18,8]) \n",
    "ax[0].set_title('a')\n",
    "ax[1].set_title('b')\n",
    "# 1행 2열의 칸을 만들고 크기는 18x8로 설정하며 1칸의 이름은 a 2칸의 이름은 b로 설정하기\n",
    "\n",
    "plt.xticks(rotation=45) \n",
    "# x인덱스 네임택 회전시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77961ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 씨본 가이드 \n",
    "sns.countplot(x = 'column',data=data) # 데이터 열 x의 바 플롯 보기\n",
    "sns.countplot(x= 'a', hue='abcd') # x를 a열값으로 설정하고 목차이름을 abcd라고 정의하기\n",
    "sns.boxplot(data['x']) # x를 박스플랏으로 표현하고 데이터를 나열하기 (아웃라이어 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 가이드\n",
    "df['Name'].str.extract('([A-Za-z]+)\\.') # 이름 중 영어이름을 점 이전까지 출력하기. 호칭출력\n",
    "for name in train['Name']:\n",
    "    titles.add(name.split(\",\")[1].split('.')[0].strip()) # 위랑 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d07eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화(스케일러) 가이드\n",
    "max(data.x)                                                  # 데이터 x의 최댓값이다.\n",
    "min(data.x)                                                  # 데이터 x의 최솟값이다.\n",
    "data.x = (data.x -min(data.x)) / (max(data.x)-min(data.x))   #데이터x의 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler               # 사이킷런 실행. 스케일러 호출\n",
    "scaler = MinMaxScaler()                                      #스케일러 함수 설정\n",
    "scaler.fit_transform(data[:])                                # 데이터 전체 스케일러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 가이드\n",
    "from sklearn.model_selection import train_test_split # 사이킷런 훈련데이터, 테스트 데이터 분리모듈\n",
    "xtrain, xtest,ytrain, ytest=train_test_split(        # 트레인데이터, 테스트데이터 분리결과\n",
    "    data.drop(['answer'],axis=1),data.answer,        # 정답 데이터 드롭한것이 트레인, 정답 데이터는 답지\n",
    "    test_size=0.2,random_state= 41                   # 테스트용으로는 20%만 사용, 랜덤값은 41로 고정\n",
    "    ,stratify = data.answer)                         # 답지는 층화추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02018755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 - 로지스틱 회귀 \n",
    "from sklearn.linear_model import LogisticRegression # 사이킷런 리니어모델 - 로지스틱 회귀\n",
    "clf = LogisticRegression()                          # 로지스틱회귀모델 제작\n",
    "clf.fit(xtrain,ytrain)                              # 모델링 절차 - 회귀모델 제작\n",
    "clf.predict(xtest)                                  # 테스트 문제풀이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수체크\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix   # 사이킷런 매트릭스, 점수체크, 혼동행렬\n",
    "accuracy_score(ytest,clf.predict(xtest))                       # 점수체크. 답지, 시험지 순으로 기재\n",
    "confusion_matrix(ytest, clf.predict(xtest))                    # 점수체크 상세표시 \n",
    "#array([[98, 12],              \n",
    "#       [23, 45]], dtype=int64) 다음과 같이 표시됨\n",
    "confusion_matrix(y_true, y_pred) # 더 많은 컨퓨전 매트릭스. \n",
    "# array([[2, 1, 0],\n",
    "#        [1, 1, 1],\n",
    "#        [0, 0, 3]], dtype=int64) # 다음과 같이 출력됨\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred),annot=True,cmap='Blues')\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수체크 2\n",
    "from sklearn.model_selection import cross_val_score         # 사이킷런 모델 평균 정확도확인\n",
    "from sklearn.ensemble import RandomForestClassifier         # 예시모델\n",
    "rcf = RandomForestClassifier(random_state=1017)             # 예시모델 생성\n",
    "scores = cross_val_score(                                   # 교차점수체크\n",
    "    rcf, data.iloc[:,:-1], data.answer,                     # 예시모델, 데이터 답제출, 데이터 정답\n",
    "    scoring = \"accuracy\", cv = 3)                           # 점수기준. 정확도 cv\n",
    "print(f\"원본 데이터 fold별 정확도: {scores}\")               # 원본정확도\n",
    "print(f\"원본 데이터 평균 정확도: {np.mean(scores):.4f}\")    # 원본평균정확도\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3일차 - KNN기반 알고리즘 만들기 \n",
    "from sklearn.preprocessing import StandardScaler   # 스케일러 호출\n",
    "from sklearn.model_selection import GridSearchCV   # 그리드서치 호출\n",
    "from sklearn.neighbors import KNeighborsClassifier # 최근접 이웃 알고리즘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()                           # 스케일러 설정\n",
    "scaler.fit(xtrain)                                  # 훈련 데이터 스케일링\n",
    "clf = KNeighborsClassifier()                        # KNN 알고리즘 모델 만들기\n",
    "params ={'n_neighbors':[3,5,7,9,11,13,15,17,19]}    # 파라미터 설정\n",
    "gs=GridSearchCV(clf, param_grid=params              # 그리드서치, 모델, 파라미터\n",
    "                , cv= 5,                            # 교차검증을 위한 폴드 횟수\n",
    "                scoring='roc_auc')                  # 스코어링 : 점수설정,['accuracy'(정확도),'roc_auc'(ROC커브),\"average_precision\"(평균기반)] \n",
    "# 그리드서치 : 이퍼파라미터를 일정한 간격으로 변경하며 최적의 파라미터를 찾는 기법\n",
    "gs.fit(xtrain,ytrain)                               # 최적화된 함수로 훈련데이터, 훈련데이터 정답 인풋\n",
    "print(gs.best_score_)                               # 모델 최고점수\n",
    "print(gs.best_estimator_)                           # 모델 최적화된 이웃갯수\n",
    "gs.predict(xtest)                                   # 테스트 문제지 대입/ 정답출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 회귀모델 - 가까운 거리에 가중치가 높음\n",
    "from sklearn.neighbors import KNeighborsRegressor              # 최근접이웃 회귀모델\n",
    "model = KNeighborsRegressor(n_neighbors=5, weights='distance') # 최근접이웃 5, 기준 거리로 모델제작\n",
    "model.fit(x_train,y_train)                                     # 모델 훈련          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4일차 의사결정트리 - k평균 알고리즘\n",
    "from sklearn.cluster import KMeans                 # K 평균 알고리즘 호출\n",
    "from sklearn.preprocessing import StandardScaler   # 스탠다드 스케일러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters = 3)                     # k평균 알고리즘 모델 생성. 클러스터 3\n",
    "model.fit(data)                                    # 모델 생성(데이터 투입)\n",
    "pred = pd.DataFrame(model.predict(feature))        # 정답지 생성하여 데이터프레임에 투입        \n",
    "model.cluster_centers_                             # 훈련 이후의 모델의 중심점들(중심좌표)\n",
    "model.cluster_centers_.shape                       # 모델의 중심점의 갯수 확인\n",
    "scaler = StandardScaler().fit(data.values)         # 스케일러로 데이터값을 스케일링 하기 \n",
    "features = scaler.transform(data.values)           # 제작된 스케일러로 데이터 스케일링\n",
    "model = KMeans(n_clusters=5,random_state=42 )      # K평균알고리즘 모델 생성, 클러스터5, 랜덤시드 42고정\n",
    "model.labels_                                      # 모델의 레이블 추출 각각 몇번의 클러스터에 속하는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69145ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘보우 그래프(위에서 이어서)\n",
    "wcss = []\n",
    "for i in range(1,20): #19번 반복\n",
    "    kmeans = KMeans(n_clusters=i,init='k-means++'  # K 근접이웃 모델생성, 클러스터선택 = i,\n",
    "                    ,max_iter=300,random_state=0)  # 초기중심점 설정 :k 근접이웃, 최대반복횟수 300, 랜덤시드 0\n",
    "    kmeans.fit(data)                               # 제작된 모델에 data 를 훈련시키기\n",
    "    wcss.append(kmeans.inertia_)                   # 군집관성을 얻어서 wcss에 추가하기\n",
    "    \n",
    "plt.plot(range(1,20),wcss)                         # 리스트 안에 있는 요소들 플랏으로 나타내기 \n",
    "plt.title('THe Elbow Curve') #엘보우 그래프        # 타이틀 이름\n",
    "plt.xlabel('Number of Clusters')                   # x라벨 이름\n",
    "plt.ylabel(\"WCSS\")                                 # y라벨 이름\n",
    "plt.show()                                         # 플랏 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5일차 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier# 랜덤포레스트 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(                       # 랜덤포레스트 분류 \n",
    "    n_estimators=1000, min_samples_split=10,       # 나무갯수, 나누는 최소단위\n",
    "    min_samples_leaf=1,random_state=42)            # 끝부분 최소크기, 랜덤시드 고정\n",
    "rf.fit(train.iloc[:,1:],train.iloc[:,0])           # 랜덤포레스트 훈련. 앞에 문제, 뒤에 답 기재\n",
    "rf.feature_importances_                            # 각 열(변수)의 중요도 확인\n",
    "pd.DataFrame(                                      # 데이터프레임으로 변환\n",
    "    rf.feature_importances_,                       # 랜덤포레스트 요소 중요도\n",
    "    columns=['importance'])),axis=1).sort_values(  # 열이름 중요도로 열에 추가\n",
    "    by='importance',ascending=False)[:20]          # 값 정렬 기준 중요도. 내림차순 정렬\n",
    "pred = rf.predict(test)                            # 테스트 정답 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6일차 부스팅 알고리즘, 랜덤포레스트 회귀\n",
    "import calendar                                    # 달력기능 호출 \n",
    "from datetime import datetime                      # 날짜 호출                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ab6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜속성 가이드 (현재 위치설정에 영향을 받음)\n",
    "pd.read_csv(\"data1.csv\",parse_dates=['datetime']) # csv 로드.\"datetime\" 열은 날짜속성을 가짐\n",
    "df['datetime'].dt.year                            # 연도 추출\n",
    "df['datetime'].dt.month                           # 월 추출\n",
    "df['datetime'].dt.day                             # 일 추출\n",
    "df['datetime'].dt.hour                            # 시간 추출\n",
    "df['datetime'].dt.minute                          # 분 추출\n",
    "list(calendar.day_name)                           # 요일 출력\n",
    "list(calendar.day_abbr)                           # 요일 축약형을 추출\n",
    "calendar.day_name[1]                              # 화요일만 출력\n",
    "datetime.today()                                  # 날짜표시\n",
    "data.datetime.strftime(\"%Y년 %m월 %d일\")          # 날짜를 문자형식으로 바꾸기\n",
    "datetime.strptime(\"202310201053\",\"%Y%m%d%H%M\")    # 문자를 날짜형식으로 바꾸기\n",
    "pd.to_numeric(train.hour)                         # 훈련데이터 시간을 숫자형식으로 바꾸기\n",
    "train['year']= pd.to_numeric(train.year)          # 훈련데이터 연도 숫자화\n",
    "train['month']= pd.to_numeric(train.month)        # 훈련데이터 월 숫자화\n",
    "train['day']= pd.to_numeric(train.day)            # 훈련데이터 일 숫자화\n",
    "train['hour']= pd.to_numeric(train.hour)          # 훈련데이터 시간 숫자화\n",
    "s.dt.weekday                                      # 요일정보 \n",
    "list(calendar.day_name)[s.dt.weekday.iloc[0]]     # 요일이름 즉시출력\n",
    "train.tempdate.apply(                             # 훈련데이터 시간칸에 추가\n",
    "    lambda x: datetime.strptime(                  # x만큼 작동하여 문자를 날짜형식으로 수정\n",
    "        x[0],\"%Y-%m-%d\").weekday())               # 날짜 추출\n",
    "train.tempdate.apply(\n",
    "    lambda x: calendar.day_name[\n",
    "        datetime.strptime(\n",
    "            x[0],\"%Y-%m-%d\").weekday()])          # 요일명 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치정보 가이드\n",
    "import locale                                     # 위치설정 호출\n",
    "locale.setlocale(locale.LC_ALL,'korean')          # 현위치 한국설정 \n",
    "locale.setlocale(locale.LC_ALL,'de_DE')           # 현위치 독일설정\n",
    "locale.setlocale(locale.LC_ALL,'english')         # 현위치 미국설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor# 랜덤포레스트 회귀 - 연속형 값을 구하는 용도로 사용\n",
    "rf = RandomForestRegressor(n_estimators=100)      # 랜덤포레스트 회귀 정의, 나무개수 100개\n",
    "rf.fit(question,answer)                           # 랜덤포레스트 회귀 훈련\n",
    "rf.predict(test)                                  # 랜덤포레스트 테스트 확인\n",
    "GridSearchCV(rf,rf_params,                        # 그리드서치, 랜덤포레스트 파라미터\n",
    "    scoring='neg_mean_poisson_deviance',cv=5)     # 점수 기준, 평균이탈, 교차검증을 위한 폴드 횟수 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5671e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드서치 \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier # 그래디언트 부스팅, 랜덤포레스트 분류\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # 훈련/테스트데이터 분할, 그리드서치\n",
    "from sklearn.metrics import accuracy_score        # 정답체크모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)       # 랜덤포레스트 분류, 랜덤시드 고정\n",
    "rf.fit(X_train, y_train)                          # 랜덤포레스트 훈련\n",
    "pred = rf.predict(X_test)                         # 모델검증\n",
    "print(\"정확도 :{0:.3f}\".format( \n",
    "    accuracy_score(y_test, pred)))                # 정확도 출력\n",
    "gb_param_grid = {                                 # 그리드서치 파라미터 설정\n",
    "    'n_estimators' : [100, 200],                  # 나무갯수 설정\n",
    "    'max_depth' : [6, 8, 10, 12],                 # 나무깊이 설정\n",
    "    'min_samples_leaf' : [3, 5, 7, 10],           # 최소 잎단위 설정\n",
    "    'min_samples_split' : [2, 3, 5, 10]           # 최소 분할단위 설정\n",
    "}\n",
    "gb = GradientBoostingClassifier(random_state=0)   # 그래디언트 부스팅 분류\n",
    "gb.fit(X_train, y_train)                          # 그래디언트 부스팅 훈련\n",
    "gb_grid = GridSearchCV(                           # 그리드서치\n",
    "    gb, param_grid = gb_param_grid,               # 기존 그래디언트 부스팅, 그리드서치 파라미터 로드\n",
    "    scoring=\"accuracy\", n_jobs= -1, verbose = 1)  # 점수기준, 정확도, 병렬처리사용 cpu 전체설정, 출력활성화\n",
    "gb_grid.fit(X_train, y_train)                     # 새로운 그래디언트 부스팅 훈련\n",
    "gb_grid.best_params_                              # 파라미터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(       # 훈련데이터/테스트데이터 분할 \n",
    "    x_features, y_target, test_size = 0.3,        # 훈련데이터셋, 타겟, 분할사이즈\n",
    "    random_state=20231023,stratify=y_target)      # 랜덤시드 고정, 타겟 층화추출법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fedee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모델\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()                     # 로지스틱 회귀모델 생성\n",
    "lr_clf.fit(X_train, y_train)                      # 로지스틱 회귀모델 훈련\n",
    "lr_clf.predict(X_test)                            # 로지스틱 회귀모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm                            # XG부스트보다 빠른 모델\n",
    "# !pip install -U imbalanced-learn                # 오버샘플링 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fb658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier              # LGBM 분류모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(                       # LGBM 분류모델 정의\n",
    "    n_estimators=1000,num_leaves=64,             # 나무갯수 천개, 잎개수 64\n",
    "    boost_from_average=False)                    # 데이터 불균형 분포 False 설정\n",
    "lgbm_clf.fit(X_train,y_train)                    # LGBM 분류모델 훈련\n",
    "lgbm_clf.predict(X_test)                         # LGBM 분류모델 평가\n",
    "lgbm_clf.predict_proba(X_test)                   # LGBM 분류모델 정답확률 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버샘플링 요령(답 비율이 매우 적을 때)\n",
    "from imblearn.over_sampling import SMOTE         # 스모트 호출\n",
    "smote = SMOTE(random_state=0)                    # 스모트 랜덤값 고정\n",
    "X_train_over,y_train_over = smote.fit_resample(  # 스모트 실행\n",
    "    X_train,y_train)                             # x훈련데이터, y훈련데이터 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이다부스트, 디시젼트리\n",
    "from sklearn.ensemble import AdaBoostClassifier # 에이다부스트 분류  \n",
    "from sklearn.tree import DecisionTreeClassifier # 디시젼트리 분류  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()               # 디시젼트리모델 생성\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)  # 에이다부스트모델 생성, 나무 100개\n",
    "dt_clf.fit(X_train,y_train)                     # 디시젼트리모델 훈련\n",
    "ada_clf.fit(X_train,y_train)                    # 에이다부스트모델 훈련\n",
    "dt_clf.predict(X_test)                          # 디시젼트레모델 평가\n",
    "ada_clf.predict(X_test)                         # 에이다부스트모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8457383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아페리오리, 장바구니 인코더\n",
    "# pip install mlxtend 아페리오리 첨부 모듈\n",
    "from mlxtend.preprocessing import TransactionEncoder            # 트랜잭션 인코더(장바구니 인코더)\n",
    "from mlxtend.frequent_patterns import apriori, association_rules# 빈발항목집합 추적 알고리즘, 연관규칙 확인모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()                      # 트랜잭션 인코더 준비\n",
    "te_ary = te.fit(dataset).transform(dataset)    # 데이터셋 훈련,데이터셋 배열 변환\n",
    "pd.DataFrame(te_ary, columns=te.columns_)      # 데이터셋 데이터프레임화\n",
    "apriori(df,min_support=0.5,use_colnames=True)  # 빈발항목 확인, 최소지지도 0.5, 열이름 확인\n",
    "association_rules(freq_itemsets)               # 연관규칙 확인, lift가 높은 것이 기준\n",
    "apriori(transactions=df_time['items'].tolist(),# 아페리오리 상세설정/ 트랜잭션항목 리스트\n",
    "        min_support=0.002,min_confidence=0.02, # 최소지지도, 최소 컨디션 수치\n",
    "        min_lift=5,min_length=2,max_length=2)  # 최소 lift 수치, 출력상품 최소길이 2 최대길이 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF, 단어의 중요도를 수치화하기\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF 호출\n",
    "from sklearn.metrics.pairwise import cosine_similarity      # 코사인유사도 호출\n",
    "from sklearn.metrics.pairwise import linear_kernel          # 코사인유사도 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 다루기\n",
    "tfidf = TfidfVectorizer()                       # TF-IDF 모델 생성\n",
    "tfidf_mat = tfidf.fit_transform(data['text'])   # TF-IDF 타겟 인풋\n",
    "tfidf_mat.get_shape()                           # TF-IDF 크기 확인\n",
    "tfidf.vocabulary_                               # 대표값 확인\n",
    "tfidf.get_feature_names_out()                   # 이름 출력\n",
    "tfidf_df = pd.DataFrame(                        \n",
    "    tfidf_mat.toarray(),                        # tfidf_mat항목을 어레이로 바꾸기\n",
    "    columns=tfidf.get_feature_names_out())      # 열 이름은 이름출력함수에 나오는 요소로 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ac214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인유사도\n",
    "cosine_similarity(tfidf_df)                     # 코사인 유사도 정의, tfidf_df로 확인\n",
    "linear_kernel(tfidf_mat,tfidf_mat)              # 코사인 유사도 정의, 같은 모양이면 둘이 서로 다른것도 비교가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ef359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어 분류기\n",
    "from konlpy.tag import Okt                                  # 한글 분류기 Okt\n",
    "from konlpy.tag import Hannanum                             # 한나눔. 성능은 낮은 편\n",
    "from konlpy.tag import Kkma                                 # 꼬꼬마. 잘 안쓰임\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF 호출\n",
    "from sklearn.feature_extraction.text import CountVectorizer # 카운터 벡터라이저.TF확인목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 분류기\n",
    "okt = Okt()                                                               # okt분류기 정의\n",
    "han = Hannanum()                                                          # 한나눔분류기 정의\n",
    "kkma = Kkma()                                                             # 꼬꼬마 분류기 정의\n",
    "print(okt.morphs(u'단독입찰보다 복수입찰의 경우'))                        # 형태소단위 추출\n",
    "print(okt.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는')) # 명사단위 추출\n",
    "print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))                # 언어속성 확인, 명사,스템\n",
    "print(okt.pos('아버지가방에들어가신다.'))\n",
    "print(han.pos('아버지가방에들어가신다.'))\n",
    "print(kkma.pos('아버지가방에들어가신다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8806e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운터 벡터라이저\n",
    "vec = CountVectorizer()                                    # 카운터 벡터라이저 정의\n",
    "vec.fit_transform(docs)                                    # dtm 형성(TF 형성) 및 배열화   \n",
    "vec.vocabulary_                                            # 열 인덱스 번호 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0169b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk : 영어 언어팩                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize                               # 영어로 된 글자를 토큰화1\n",
    "from nltk.tokenize import WordPunctTokenizer                          # 영어로 된 글자를 토큰화2\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence # 영어로 된 글자를 토큰화3\n",
    "from nltk.tokenize import sent_tokenize                               # 문장을 문단으로 토큰화\n",
    "from nltk.stem import WordNetLemmatizer                               # 표제어 추출기\n",
    "from nltk.stem import PorterStemmer                                   # 포토스테머 :스태밍용\n",
    "from nltk.stem import LancasterStemmer                                # 래케스트스태머\n",
    "from nltk.corpus import stopwords                                     # 불용어 제거모듈\n",
    "\n",
    "# 단어 토큰화 모듈 애러시\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "\n",
    "# 불용어 모듈 애러시\n",
    "import nltk \n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 토큰화 확인\n",
    "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
    "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
    "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
    "# 확인해보고 적정한 토크나이저 사용하기.\n",
    "print('문장 토큰화1 :',sent_tokenize(\"I am actively looking for Ph.D. students. and you are a Ph.D student.\"))\n",
    "# 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2424cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 언어팩\n",
    "lemmatizer = WordNetLemmatizer()                                         # 표제어추출기\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print('표제어 추출 전 :',words)                                          # 표제어추출전\n",
    "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words]) # 표제어추출후\n",
    "lemmatizer.lemmatize('watching','v')                                     # 동사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d361c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태머.어간 추출하기\n",
    "stemmer = PorterStemmer()                                              # 포터스태머 설정\n",
    "lancaster_stemmer = LancasterStemmer()                                 # 래케스트 스태머\n",
    "words = ['formalize', 'allowance', 'electricical']                     # 어간을 추출할 대상이다.\n",
    "print('어간 추출 후 :',[stemmer.stem(word) for word in words])         # 포터스태머 추출 반복\n",
    "print('어간 추출 후 :',[lancaster_stemmer.stem(word) for word in words]# 래케스트스태머 추출반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stopwords.words('english')                                             # 영어 불용어 확인\n",
    "stop_words = set(stopwords.words('english'))                           # 불용어 언어목록 할당\n",
    "word_tokens = word_tokenize(word)                                      # 단어를 토큰화해서 할당\n",
    "\n",
    "result = []                                                            # 결과담는 리스트\n",
    "for word in word_tokens:                                               # 토큰화된 단어 순환\n",
    "    if word not in stop_words:                                         # 단어가 불용어가 아닐 시\n",
    "        result.append(word)                                            # 단어를 리스트에 추가\n",
    "print('불용어 제거 전 :',word_tokens)                                  # 결과확인\n",
    "print('불용어 제거 후 :',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 서프라이즈\n",
    "# pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27316d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                                        # 랜덤모듈\n",
    "from surprise import accuracy                        # 정확도 확인\n",
    "from surprise import Dataset                         # 데이터셋\n",
    "from surprise import Reader                          # 리더모듈\n",
    "from surprise import SVD                             # SVD\n",
    "from surprise.model_selection import GridSearchCV    # 그리드서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 서프라이즈\n",
    "reader = Reader(rating_scale=(1,5))                  # 점수는 1점부터 5점까지. 예)영화평점 시스템\n",
    "data = Dataset.load_from_df(                         # 서프라이즈 사용 데이터 설정\n",
    "    ratings_data[['user_id','book_id','rating']],    # 기존 데이터'ratings_data'에서 할당\n",
    "    reader)                                          # 점수설정\n",
    "raw_ratings = data.raw_ratings                       # 아이디. 상품id, 점수 나열하기 \n",
    "random.shuffle(raw_ratings)                          # 데이터 순서 랜덤으로 섞기\n",
    "test = data.construct_testset(raw_ratings_test)      # 테스트 데이터셋 설정\n",
    "\n",
    "param_grid = {                                       # SVD 그리드 서치\n",
    "    \"n_factors\": [25, 40, 55],                       # 요인의 숫자 디폴트 100\n",
    "    \"n_epochs\": [10, 20],                            # 반복하는 숫자, 디폴트 20\n",
    "    \"lr_all\": [0.005, 0.025, 0.125],                 # 러닝메이트 \n",
    "    \"reg_all\": [0.08, 0.16, 0.32],                   # 정규항\n",
    "    \"random_state\": [0],                             # 랜덤값 고정\n",
    "}\n",
    "grid_search = GridSearchCV(                          # 그리드서치 정의\n",
    "    SVD,                                             # SVD 사용\n",
    "    param_grid,                                      # 그리드서치 항목\n",
    "    measures=[\"rmse\", \"mae\"],                        # 측정기준, rmse, mae\n",
    "    cv=3,                                            # cv 3\n",
    "    refit=True,                                      # \n",
    "    n_jobs=-1,                                       # cpu 할당 전체\n",
    "    joblib_verbose=2                                 # 안내문 2 활성화\n",
    ")\n",
    "grid_search.fit(data)                                # 그리드 서치 기반 모델생성\n",
    "best_model = grid_search.best_estimator['rmse']      # 생성된 모델 중 최고의 모델을 출력\n",
    "raw_ratings_test_predictions = best_model.test(test) # 모델 평가 및 저장\n",
    "accuracy.rmse(raw_ratings_test_predictions)          # 정확도 확인\n",
    "grid_search.best_params                              # 현재의 그리드서치 파라미터 확인\n",
    "\n",
    "svd = SVD()                                          # SVD 직접사용\n",
    "svd.fit(trainset)                                    # SVD 모델 훈련\n",
    "pred = svd.test(testset)                             # SVD 모델 평가, 저장\n",
    "accuracy.rmse(pred)                                  # 제곱근 정확도 확인 \n",
    "accuracy.mae(pred)                                   # 절대값 정확도 확인\n",
    "svd.predict(str(907), str(143))                      # 결과 미리 확인하기(예시 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df884443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타 - 코사인유사도 활용하기\n",
    "listyy = []\n",
    "ans[0][0] = 0\n",
    "for i in range(1,500):\n",
    "    if ans[0][i] >= 1:\n",
    "        print(data['title'].iloc[i])\n",
    "        listyy.append(data['title'].iloc[i])\n",
    "        ans[0][i] = 0\n",
    "        print(listyy)\n",
    "while len(listyy) < 10:\n",
    "    listyy.append(data['title'].iloc[np.argmax(ans[0])])\n",
    "    ans[0][np.argmax(ans[0])] = 0    \n",
    "print(listyy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe94325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타 - idf 행렬 정렬하기\n",
    "result = []\n",
    "for j in range(len(vocab)): \n",
    "    t = vocab[j] # 각각의 단어를 t에 대입했다. \n",
    "    result.append(idf(t)) # idf값으로 계산하여 결과값에 대입한다.\n",
    "\n",
    "idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"]) #행의 이름을  각 단어들로 했고 열값을 IDF라고 정의했다. \n",
    "idf_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타 - 한국어 불용어 제거 예시\n",
    "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\" \n",
    "\n",
    "stop_words = set(stop_words.split(' ')) \n",
    "word_tokens = okt.morphs(example) \n",
    "\n",
    "result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print('불용어 제거 전 :',word_tokens) \n",
    "print('불용어 제거 후 :',result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
